@inproceedings{Miltsakaki,
 author = {Miltsakaki, Eleni and Robaldo, Livio and Lee, Alan and Joshi, Aravind},
 title = {Sense Annotation in the Penn Discourse Treebank},
 booktitle = {Proceedings of the 9th International Conference on Computational Linguistics and Intelligent Text Processing},
 series = {CICLing'08},
 year = {2008},
 isbn = {3-540-78134-X, 978-3-540-78134-9},
 location = {Haifa, Israel},
 pages = {275--286},
 numpages = {12},
 url = {http://dl.acm.org/citation.cfm?id=1787578.1787605},
 acmid = {1787605},
 publisher = {Springer-Verlag},
 address = {Berlin, Heidelberg},
}

@article{wolf2005representing,
  title={Representing discourse coherence: A corpus-based study},
  author={Wolf, Florian and Gibson, Edward},
  journal={Computational linguistics},
  volume={31},
  number={2},
  pages={249--287},
  year={2005},
  publisher={MIT Press}
}

@inproceedings{yung2019crowdsourcing,
  title={Crowdsourcing Discourse Relation Annotations by a Two-Step Connective Insertion Task},
  author={Yung, Frances and Demberg, Vera and Scholman, Merel},
  booktitle={Proceedings of the 13th Linguistic Annotation Workshop},
  pages={16--25},
  year={2019}
}

@article{mann1988rhetorical,
  title={Rhetorical {S}tructure {T}heory: {T}oward a functional theory of text organization},
  author={Mann, William C and Thompson, Sandra A},
  journal={Text \& Talk},
  volume={8},
  number={3},
  pages={243--281},
  year={1988},
  publisher={Walter de Gruyter, Berlin/New York},
  doi = "https://doi.org/10.1515/text.1.1988.8.3.243",
  url = "https://www.degruyter.com/view/journals/text/8/3/article-p243.xml"
}


@book{carlson2002rst,
  title={RST Discourse Treebank},
  author={Carlson, Lynn and Okurowski, Mary Ellen and Marcu, Daniel},
  year={2002},
  publisher={Linguistic Data Consortium, University of Pennsylvania},
  url = {https://catalog.ldc.upenn.edu/LDC2002T07}
}

@inproceedings{devlin_bert:_2019,
	location = {Minneapolis, Minnesota},
	title = {{BERT}: {P}re-training of {D}eep {B}idirectional {T}ransformers for {L}anguage {U}nderstanding},
	url = {https://www.aclweb.org/anthology/N19-1423},
	abstract = {We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), {BERT} is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. {BERT} is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the {GLUE} score to 80.5 (7.7 point absolute improvement), {MultiNLI} accuracy to 86.7\% (4.6\% absolute improvement), {SQuAD} v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and {SQuAD} v2.0 Test F1 to 83.1 (5.1 point absolute improvement).},
	pages = {4171--4186},
	booktitle = {Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
	publisher = {Association for Computational Linguistics},
	author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	date = {2019-06},
	address = {Minneapolis, Minnesota},
	year={2019}
}

@article{Wolf2019HuggingFacesTS,
  title={{H}uggingFace's {T}ransformers: {S}tate-of-the-art {N}atural {L}anguage {P}rocessing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},
  journal={Computing Research Repository},
  volume={arXiv:1910.03771},
  year={2019},
  url={https://arxiv.org/abs/1910.03771}
}

@article{liu2019roberta,
  title={Ro{BERT}a: A {R}obustly {O}ptimized {BERT} {P}retraining {A}pproach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={Computing Research Repository},
  volume={arXiv:1907.11692},
  url="https://arxiv.org/abs/1907.11692",
  year={2019}
}

@inproceedings{
loshchilov2018decoupled,
title={{D}ecoupled {W}eight {D}ecay {R}egularization},
author={Ilya Loshchilov and Frank Hutter},
booktitle={International Conference on Learning Representations},
year={2019},
url={https://openreview.net/forum?id=Bkg6RiCqY7},
}

@inproceedings{reimers-gurevych-2019-sentence,
    title = "Sentence-{BERT}: Sentence Embeddings using {S}iamese {BERT}-Networks",
    author = "Reimers, Nils  and
      Gurevych, Iryna",
    booktitle = "Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)",
    month = nov,
    year = "2019",
    address = "Hong Kong, China",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D19-1410",
    doi = "10.18653/v1/D19-1410",
    pages = "3982--3992",
    abstract = "BERT (Devlin et al., 2018) and RoBERTa (Liu et al., 2019) has set a new state-of-the-art performance on sentence-pair regression tasks like semantic textual similarity (STS). However, it requires that both sentences are fed into the network, which causes a massive computational overhead: Finding the most similar pair in a collection of 10,000 sentences requires about 50 million inference computations ({\textasciitilde}65 hours) with BERT. The construction of BERT makes it unsuitable for semantic similarity search as well as for unsupervised tasks like clustering. In this publication, we present Sentence-BERT (SBERT), a modification of the pretrained BERT network that use siamese and triplet network structures to derive semantically meaningful sentence embeddings that can be compared using cosine-similarity. This reduces the effort for finding the most similar pair from 65 hours with BERT / RoBERTa to about 5 seconds with SBERT, while maintaining the accuracy from BERT. We evaluate SBERT and SRoBERTa on common STS tasks and transfer learning tasks, where it outperforms other state-of-the-art sentence embeddings methods.",
}


@inproceedings{vaswani_attention_2017,
	title = {Attention is {A}ll you {N}eed},
author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser,  ≈Åukasz and Polosukhin, Illia},
booktitle = {Advances in Neural Information Processing Systems 30},
editor = {I. Guyon and U. V. Luxburg and S. Bengio and H. Wallach and R. Fergus and S. Vishwanathan and R. Garnett},
pages = {5998--6008},
year = {2017},
publisher = {Curran Associates, Inc.},
url = {https://papers.nips.cc/paper/7181-attention-is-all-you-need}
}


@inproceedings{yang_xlnet_2019,
	title = {{XLNet}: {G}eneralized {A}utoregressive {P}retraining for {L}anguage {U}nderstanding},
	pages = {5754--5764},
	booktitle = {Advances in {N}eural {I}nformation {P}rocessing {S}ystems},
	author = {Yang, Zhilin and Dai, Zihang and Yang, Yiming and Carbonell, Jaime and Salakhutdinov, Russ R and Le, Quoc V},
	date = {2019},
	year = {2019},
	url = "http://papers.nips.cc/paper/8812-xlnet-generalized-autoregressive-pretraining-for-language-understanding"
}

@article{zellers2020evaluating,
  title={Evaluating {M}achines by their {R}eal-{W}orld {L}anguage {U}se},
  author={Zellers, Rowan and Holtzman, Ari and Clark, Elizabeth and Qin, Lianhui and Farhadi, Ali and Choi, Yejin},
  journal={Computing Research Repository},
  volume={arXiv:2004.03607},
  url={https://arxiv.org/abs/2004.03607},
  year={2020}
}


@article{dawid_maximum_1979,
	title = {{M}aximum {L}ikelihood {E}stimation of {O}bserver {E}rror-{R}ates {U}sing the {EM} {A}lgorithm},
	volume = {28},
	issn = {00359254, 14679876},
	url = {www.jstor.org/stable/2346806},
	doi = {10.2307/2346806},
	abstract = {[In compiling a patient record many facets are subject to errors of measurement. A model is presented which allows individual error-rates to be estimated for polytomous facets even when the patient's "true" response is not available. The {EM} algorithm is shown to provide a slow but sure way of obtaining maximum likelihood estimates of the parameters of interest. Some preliminary experience is reported and the limitations of the method are described.]},
	pages = {20--28},
	number = {1},
	journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
	author = {Dawid, A. P. and Skene, A. M.},
	urldate = {2020-05-04},
	date = {1979},
	year = {1979},
	publisher = {Wiley, Royal Statistical Society}
}

@inproceedings{stenetorp-etal-2012-brat,
    title = "{\scshape BRAT}: a {W}eb-based {T}ool for {NLP}-{A}ssisted {T}ext {A}nnotation",
    author = "Stenetorp, Pontus  and
      Pyysalo, Sampo  and
      Topi{\'c}, Goran  and
      Ohta, Tomoko  and
      Ananiadou, Sophia  and
      Tsujii, Jun{'}ichi",
    booktitle = "Proceedings of the Demonstrations at the 13th Conference of the {E}uropean Chapter of the Association for Computational Linguistics",
    month = apr,
    year = "2012",
    address = "Avignon, France",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/E12-2021",
    pages = "102--107",
}


@article{cohen_coefficient_1960,
	title = {A {C}oefficient of {A}greement for {N}ominal {S}cales},
	volume = {20},
	issn = {0013-1644},
	url = {https://doi.org/10.1177/001316446002000104},
	doi = {10.1177/001316446002000104},
	pages = {37--46},
	number = {1},
	journal = {Educational and Psychological Measurement},
	shortjournal = {Educational and Psychological Measurement},
	author = {Cohen, Jacob},
	urldate = {2020-05-04},
	date = {1960-04-01},
	year={1960},
	note = {Publisher: {SAGE} Publications Inc}
}

@inproceedings{wang-etal-2018-toward,
    title = "Toward {F}ast and {A}ccurate {N}eural {D}iscourse {S}egmentation",
    author = "Wang, Yizhong  and
      Li, Sujian  and
      Yang, Jingfeng",
    booktitle = "Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing",
    month = oct # "-" # nov,
    year = "2018",
    address = "Brussels, Belgium",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D18-1116",
    doi = "10.18653/v1/D18-1116",
    pages = "962--967",
    abstract = "Discourse segmentation, which segments texts into Elementary Discourse Units, is a fundamental step in discourse analysis. Previous discourse segmenters rely on complicated hand-crafted features and are not practical in actual use. In this paper, we propose an end-to-end neural segmenter based on BiLSTM-CRF framework. To improve its accuracy, we address the problem of data insufficiency by transferring a word representation model that is trained on a large corpus. We also propose a restricted self-attention mechanism in order to capture useful information within a neighborhood. Experiments on the RST-DT corpus show that our model is significantly faster than previous methods, while achieving new state-of-the-art performance.",
}

@unpublished{spacy2,
    AUTHOR = {Honnibal, Matthew and Montani, Ines},
    TITLE  = {{spaCy 2}: Natural language understanding with {B}loom embeddings, convolutional neural networks and incremental parsing},
    YEAR   = {2017},
    Note   = {}
}

@book{loper2002nltk,
  title={Natural {L}anguage {P}rocessing with {P}ython},
  author={Loper, Edward and Bird, Steven},
  publisher={O‚ÄôReilly Media Inc.},
  url={http://www.nltk.org},
  year={2009}
}

@inproceedings{parde-nielsen-2017-finding,
    title = "Finding {P}atterns in {N}oisy {C}rowds: {R}egression-based {A}nnotation {A}ggregation for {C}rowdsourced {D}ata",
    author = "Parde, Natalie  and
      Nielsen, Rodney",
    booktitle = "Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing",
    month = sep,
    year = "2017",
    address = "Copenhagen, Denmark",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D17-1204",
    doi = "10.18653/v1/D17-1204",
    pages = "1907--1912",
    abstract = "Crowdsourcing offers a convenient means of obtaining labeled data quickly and inexpensively. However, crowdsourced labels are often noisier than expert-annotated data, making it difficult to aggregate them meaningfully. We present an aggregation approach that learns a regression model from crowdsourced annotations to predict aggregated labels for instances that have no expert adjudications. The predicted labels achieve a correlation of 0.594 with expert labels on our data, outperforming the best alternative aggregation method by 11.9{\%}. Our approach also outperforms the alternatives on third-party datasets.",
}

@inproceedings{negi-etal-2019-semeval,
    title = "{S}em{E}val-2019 {T}ask 9: {S}uggestion {M}ining from {O}nline {R}eviews and {F}orums",
    author = "Negi, Sapna  and
      Daudert, Tobias  and
      Buitelaar, Paul",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S19-2151",
    doi = "10.18653/v1/S19-2151",
    pages = "877--887",
    abstract = "We present the pilot SemEval task on Suggestion Mining. The task consists of subtasks A and B, where we created labeled data from feedback forum and hotel reviews respectively. Subtask A provides training and test data from the same domain, while Subtask B evaluates the system on a test dataset from a different domain than the available training data. 33 teams participated in the shared task, with a total of 50 members. We summarize the problem definition, benchmark dataset preparation, and methods used by the participating teams, providing details of the methods used by the top ranked systems. The dataset is made freely available to help advance the research in suggestion mining, and reproduce the systems submitted under this task",
}

@inproceedings{potamias-etal-2019-ntua,
    title = "{NTUA}-{ISL}ab at {S}em{E}val-2019 Task 9: {M}ining {S}uggestions in the wild",
    author = "Potamias, Rolandos Alexandros and
      Neofytou, Alexandros  and
      Siolas, Georgios",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/S19-2215",
    doi = "10.18653/v1/S19-2215",
    pages = "1224--1230",
    abstract = "As online customer forums and product comparison sites increase their societal influence, users are actively expressing their opinions and posting their recommendations on their fellow customers online. However, systems capable of recognizing suggestions still lack in stability. Suggestion Mining, a novel and challenging field of Natural Language Processing, is increasingly gaining attention, aiming to track user advice on online forums. In this paper, a carefully designed methodology to identify customer-to-company and customer-to-customer suggestions is presented. The methodology implements a rule-based classifier using heuristic, lexical and syntactic patterns. The approach ranked at 5th and 1st position, achieving an f1-score of 0.749 and 0.858 for SemEval-2019/Suggestion Mining sub-tasks A and B, respectively. In addition, we were able to improve performance results by combining the rule-based classifier with a recurrent convolutional neural network, that exhibits an f1-score of 0.79 for subtask A.",
}

@inproceedings{cho-etal-2014-learning,
    title = "Learning Phrase Representations using {RNN} Encoder{--}Decoder for Statistical Machine Translation",
    author = {Cho, Kyunghyun  and
      van Merri{\"e}nboer, Bart  and
      Gulcehre, Caglar  and
      Bahdanau, Dzmitry  and
      Bougares, Fethi  and
      Schwenk, Holger  and
      Bengio, Yoshua},
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D14-1179",
    doi = "10.3115/v1/D14-1179",
    pages = "1724--1734",
}

@book{smith_2003,
    place={Cambridge},
    series={Cambridge Studies in Linguistics},
    title={Modes of Discourse: The Local Structure of Texts},
    DOI={10.1017/CBO9780511615108},
    publisher={Cambridge University Press},
    author={Smith, Carlota S.},
    year={2003},
    collection={Cambridge Studies in Linguistics}
}

@inproceedings{vig2019transformervis,
    title = "A {M}ultiscale {V}isualization of {A}ttention in the {T}ransformer {M}odel",
    author = "Vig, Jesse",
    booktitle = "Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations",
    month = jul,
    year = "2019",
    address = "Florence, Italy",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P19-3007",
    doi = "10.18653/v1/P19-3007",
    pages = "37--42",
    abstract = "The Transformer is a sequence model that forgoes traditional recurrent architectures in favor of a fully attention-based approach. Besides improving performance, an advantage of using attention is that it can also help to interpret a model by showing how the model assigns weight to different input elements. However, the multi-layer, multi-head attention mechanism in the Transformer model can be difficult to decipher. To make the model more accessible, we introduce an open-source tool that visualizes attention at multiple scales, each of which provides a unique perspective on the attention mechanism. We demonstrate the tool on BERT and OpenAI GPT-2 and present three example use cases: detecting model bias, locating relevant attention heads, and linking neurons to model behavior.",
}

@inproceedings{
Clark2020ELECTRA,
title={{ELECTRA}: {P}re-training {T}ext {E}ncoders as {D}iscriminators {R}ather {T}han {G}enerators},
author={Kevin Clark and Minh-Thang Luong and Quoc V. Le and Christopher D. Manning},
booktitle={International Conference on Learning Representations},
year={2020},
url={https://openreview.net/forum?id=r1xMH1BtvB}
}

@article{abolfathiasl2013pragmatic,
	author = {Hossein Abolfathiasl and Ain Nadzimah Abdullah},
	title = {{P}ragmatic {S}trategies and {L}inguistic {S}tructures in {M}aking ‚Äò{S}uggestions‚Äô: {T}owards {C}omprehensive {T}axonomies},
	journal = {International Journal of Applied Linguistics and English Literature},
	volume = {2},
	number = {6},
	year = {2013},
	keywords = {Speech act of suggesting, pragmatic strategy, linguistic structure, taxonomy},
	abstract = {This paper analyses and upgrades taxonomies of strategies and structures for the speech act of suggesting based on existing taxonomies and classifications in the pragmatics research literature. Previous studies have focused mainly on linguistic structures used to perform the speech act of suggesting. Thus, there seems to be a need to provide a more comprehensive set of taxonomies for structures as well as strategies that can be used in EFL/ESL classrooms and for research on the speech act of suggesting. To this end, the speech act of suggesting is defined first and the features of this speech act are discussed. Second, the most recent classifications proposed for structures and linguistic realization strategies for suggestions were analysed and contrasted and a more comprehensive taxonomy of structures and linguistic realization strategies is provided, based on previous taxonomies. Finally, taxonomy of politeness strategies in making suggestions are provided, based on recent studies in cross-cultural pragmatics research.},
	issn = {2200-3452},
	pages = {236--241},
	doi = {10.7575/aiac.ijalel.v.2n.6p.236},
	url = {https://www.journals.aiac.org.au/index.php/IJALEL/article/view/981}
}

@article{ettinger2020bert,
author = {Ettinger, Allyson},
title = {What {BERT} {I}s {N}ot: {L}essons from a {N}ew {S}uite of {P}sycholinguistic {D}iagnostics for {L}anguage {M}odels},
journal = {Transactions of the Association for Computational Linguistics},
volume = {8},
number = {},
pages = {34-48},
year = {2020},
doi = {10.1162/tacl_a_00298},

URL = {
        https://doi.org/10.1162/tacl_a_00298

},
    abstract = { Pre-training by language modeling has become a popular and successful approach to NLP tasks, but we have yet to understand exactly what linguistic capacities these pre-training processes confer upon models. In this paper we introduce a suite of diagnostics drawn from human language experiments, which allow us to ask targeted questions about information used by language models for generating predictions in context. As a case study, we apply these diagnostics to the popular BERT model, finding that it can generally distinguish good from bad completions involving shared category or role reversal, albeit with less sensitivity than humans, and it robustly retrieves noun hypernyms, but it struggles with challenging inference and role-based event prediction‚Äî and, in particular, it shows clear insensitivity to the contextual impacts of negation. }
}




@inproceedings{nye-etal-2018-corpus,
    title = "A {C}orpus with {M}ulti-{L}evel {A}nnotations of {P}atients, {I}nterventions and {O}utcomes to {S}upport {L}anguage {P}rocessing for {M}edical {L}iterature",
    author = "Nye, Benjamin  and
      Li, Junyi Jessy  and
      Patel, Roma  and
      Yang, Yinfei  and
      Marshall, Iain  and
      Nenkova, Ani  and
      Wallace, Byron",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1019",
    doi = "10.18653/v1/P18-1019",
    pages = "197--207",
    abstract = "We present a corpus of 5,000 richly annotated abstracts of medical articles describing clinical randomized controlled trials. Annotations include demarcations of text spans that describe the Patient population enrolled, the Interventions studied and to what they were Compared, and the Outcomes measured (the {`}PICO{'} elements). These spans are further annotated at a more granular level, e.g., individual interventions within them are marked and mapped onto a structured medical vocabulary. We acquired annotations from a diverse set of workers with varying levels of expertise and cost. We describe our data collection process and the corpus itself in detail. We then outline a set of challenging NLP tasks that would aid searching of the medical literature and the practice of evidence-based medicine.",
}

@misc{pdtb,
title={{P}enn {D}iscourse {T}reebank {V}ersion 2.0 {A}nnotation {M}anual},
author={Prasad, Rashmi and Miltsakaki, Eleni and Dinesh, Nikhil and Lee, Alan and Joshi, Aravind},
year={2003},
url={https://www.seas.upenn.edu/~pdtb/PDTBAPI/pdtb-annotation-manual.pdf},
}

@inproceedings{cachola2018expressively,
    title = "Expressively vulgar: The socio-dynamics of vulgarity and its effects on sentiment analysis in social media",
    author = "Cachola, Isabel  and
      Holgate, Eric  and
      Preo{\c{t}}iuc-Pietro, Daniel  and
      Li, Junyi Jessy",
    booktitle = "Proceedings of the 27th International Conference on Computational Linguistics",
    month = aug,
    year = "2018",
    address = "Santa Fe, New Mexico, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/C18-1248",
    pages = "2927--2938",
    abstract = "Vulgarity is a common linguistic expression and is used to perform several linguistic functions. Understanding their usage can aid both linguistic and psychological phenomena as well as benefit downstream natural language processing applications such as sentiment analysis. This study performs a large-scale, data-driven empirical analysis of vulgar words using social media data. We analyze the socio-cultural and pragmatic aspects of vulgarity using tweets from users with known demographics. Further, we collect sentiment ratings for vulgar tweets to study the relationship between the use of vulgar words and perceived sentiment and show that explicitly modeling vulgar words can boost sentiment analysis performance.",
}


@article{decapua_strategies_1993,
	title = {Strategies in the discourse of advice},
	volume = {20},
	issn = {0378-2166},
	url = {http://www.sciencedirect.com/science/article/pii/037821669390014G},
	doi = {10.1016/0378-2166(93)90014-G},
	abstract = {This paper reports the findings of a continuing investigation of advice in American English. Our purpose here was to identify and analyze action patterns (discourse strategies) which speakers use in requesting and giving advice in the context of radio advice programs. Three strategies found in the advising discourse were explanation, elaboration and narration. The data were collected from two radio advice programs broadcast by {WOR} radio in New York City: the Bernard Meltzer program and the Sally Jessy Rapha√´l program. Advice givers seem to have three major goals: to help callers clarify their problems, to help them explore their options, and to offer direction, usually regarding some action to be taken in the future.},
	pages = {519--531},
	number = {6},
	journal = {Journal of Pragmatics},
	shortjournal = {Journal of Pragmatics},
	author = {{DeCapua}, Andrea and Dunham, Joan Findlay},
	urldate = {2020-08-07},
	year = {1993},
	date = {1993-12-01},
	langid = {english}
}


@article{shaw_managing_2013,
	title = {Managing the {M}oral {I}mplications of {A}dvice in {I}nformal {I}nteraction},
	volume = {46},
	issn = {0835-1813},
	url = {https://doi.org/10.1080/08351813.2013.839095},
	doi = {10.1080/08351813.2013.839095},
	abstract = {What does advice giving look like among family members? Most conversation analytic research on advice has been in institutional settings, which constrain what speakers can do. Here we analyze advice in the apparently freer environment of telephone calls between mothers and their young adult daughters. We concentrate on how the advice is received. Our analysis shows that the position of ‚Äúadvice recipient‚Äù is a potentially unwelcome identity to occupy because it implies one knows less than the advice giver and indeed that one may be somehow at fault. Advice can be resisted, but choosing to do so seems to depend on what the interactional costs would be. We discuss the implications for studying advice and promoting advice acceptance as well as the way relationality more generally can be constituted in talk.},
	pages = {344--362},
	number = {4},
	journal = {Research on Language and Social Interaction},
	author = {Shaw, Chloe and Hepburn, Alexa},
	urldate = {2020-08-07},
	date = {2013-10-01},
	year={2013},
	publisher= {Routledge},
}

@inproceedings{fu-etal-2019-asking,
    title = "{A}sking the {R}ight {Q}uestion: {I}nferring {A}dvice-{S}eeking {I}ntentions from {P}ersonal {N}arratives",
    author = "Fu, Liye  and
      Chang, Jonathan P.  and
      Danescu-Niculescu-Mizil, Cristian",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1052",
    doi = "10.18653/v1/N19-1052",
    pages = "528--541",
    abstract = "People often share personal narratives in order to seek advice from others. To properly infer the narrator{'}s intention, one needs to apply a certain degree of common sense and social intuition. To test the capabilities of NLP systems to recover such intuition, we introduce the new task of inferring what is the advice-seeking goal behind a personal narrative. We formulate this as a cloze test, where the goal is to identify which of two advice-seeking questions was removed from a given narrative. The main challenge in constructing this task is finding pairs of semantically plausible advice-seeking questions for given narratives. To address this challenge, we devise a method that exploits commonalities in experiences people share online to automatically extract pairs of questions that are appropriate candidates for the cloze task. This results in a dataset of over 20,000 personal narratives, each matched with a pair of related advice-seeking questions: one actually intended by the narrator, and the other one not. The dataset covers a very broad array of human experiences, from dating, to career options, to stolen iPads. We use human annotation to determine the degree to which the task relies on common sense and social intuition in addition to a semantic understanding of the narrative. By introducing several baselines for this new task we demonstrate its feasibility and identify avenues for better modeling the intention of the narrator.",
}

@inproceedings{nye-nenkova-2015-identification,
    title = "Identification and {C}haracterization of {N}ewsworthy {V}erbs in {W}orld {N}ews",
    author = "Nye, Benjamin  and
      Nenkova, Ani",
    booktitle = "Proceedings of the 2015 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = may # "{--}" # jun,
    year = "2015",
    address = "Denver, Colorado",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N15-1166",
    doi = "10.3115/v1/N15-1166",
    pages = "1440--1445",
}

@misc{pewstudy,
  title="Information {T}riage",
  author="Susannah Fox and Maeve Duggan",
  journal="Health Online",
  year="2013",
  url = {https://www.pewresearch.org/internet/2013/01/15/information-triage/},
  note = {Pew Research Center: Internet, Science \& Tech}
}

@article{chen2018health,
	title = {Health {I}nformation {O}btained {F}rom the {I}nternet and {C}hanges in {M}edical {D}ecision {M}aking: {Q}uestionnaire {D}evelopment and {C}ross-{S}ectional {S}urvey},
	volume = {20},
	issn = {1438-8871},
	doi = {10.2196/jmir.9370},
	shorttitle = {Health Information Obtained From the Internet and Changes in Medical Decision Making},
	pages = {e47},
	number = {2},
	journal = {Journal of Medical Internet Research},
	author = {Chen, Yen-Yuan and Li, Chia-Ming and Liang, Jyh-Chong and Tsai, Chin-Chung},
	year = {2018},
	pmid = {29434017},
	pmcid = {PMC5826978},
	keywords = {Clinical Decision-Making, Cross-Sectional Studies, decision making, Female, Health Behavior, help-seeking behavior, Humans, Information Seeking Behavior, internet, Internet, literacy, Male, Medical Informatics, Surveys and Questionnaires}
}

@article{monroe_colaresi_quinn_2017, title={Fightin' {W}ords: {L}exical {F}eature {S}election and {E}valuation for {I}dentifying the {C}ontent of {P}olitical {C}onflict}, volume={16}, DOI={10.1093/pan/mpn018}, number={4}, journal={Political Analysis}, publisher={Cambridge University Press}, author={Monroe, Burt L. and Colaresi, Michael P. and Quinn, Kevin M.}, year={2017}, pages={372‚Äì403}}